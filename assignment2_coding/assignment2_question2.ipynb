{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitce8c704d4b604f999a41d2b2fe543311",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from the package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import datapackage\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "data_url = 'https://datahub.io/machine-learning/tic-tac-toe/datapackage.json'\n",
    "\n",
    "# to load Data Package into storage\n",
    "package = datapackage.Package(data_url)\n",
    "\n",
    "# to load only tabular data\n",
    "resources = package.resources\n",
    "for resource in resources:\n",
    "    if resource.tabular:\n",
    "        data_tic_tak = pd.read_csv(resource.descriptor['path'])\n",
    "        #print (data)\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "data_tic_tak  = pd.read_csv(\"./tic-tac-toe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['top-left-square' 'top-middle-square' 'top-right-square'\n 'middle-left-square' 'middle-middle-square' 'middle-right-square'\n 'bottom-left-square' 'bottom-middle-square' 'bottom-right-square' 'Class']\n958\n"
    }
   ],
   "source": [
    "#print(data.head())\n",
    "attributes = data_tic_tak.columns.values\n",
    "print(attributes)\n",
    "attribute_values = data_tic_tak.iloc[:,0:9]\n",
    "#print(attribute_values)\n",
    "class_labels  = data_tic_tak.iloc[:,9]\n",
    "#print(class_labels)\n",
    "\n",
    "#decisionTree = DecisionTree(attribute_values, attributes, class_labels)\n",
    "print(len(class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['top-left-square' 'top-middle-square' 'top-right-square'\n 'middle-left-square' 'middle-middle-square' 'middle-right-square'\n 'bottom-left-square' 'bottom-middle-square' 'bottom-right-square']\n"
    }
   ],
   "source": [
    "#print(data[(data['top-middle-square'] == 'x')])\n",
    "#print(data)\n",
    "d1 = data_tic_tak['Class']\n",
    "d2 = d1.loc[d1 == 'positive']\n",
    "#print(d2)\n",
    "attributes = data_tic_tak.iloc[:,0:9].columns.values\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "import operator\n",
    "\n",
    "def CalEntropy(data, column_name):\n",
    "    '''\n",
    "    '''\n",
    "    #print(\"***********\", column_name)\n",
    "    total_data_samples = len(data)\n",
    "    #print(\"Total data samples\", total_data_samples)\n",
    "\n",
    "    col_feature_values = data[column_name]\n",
    "    (vals, vals_count) = np.unique(col_feature_values, return_counts=True)\n",
    "    #print(\"Values in the colum and there count\", vals, vals_count)\n",
    "\n",
    "    label_values = data.iloc[:,-1]\n",
    "    class_labels  = np.unique(label_values)\n",
    "    #print(\"Class Labels\", class_labels)\n",
    "\n",
    "    data_temp =  pd.concat([col_feature_values, label_values], axis=1)\n",
    "    #print(data_temp.head())\n",
    "\n",
    "    #class count for each feature variable\n",
    "    #dictionary structure {'attribute value': [negetive sample, positive_sample]}\n",
    "    label_count_dict = {}\n",
    "    #print(data_temp.head())\n",
    "    for x in vals:\n",
    "        #print(column_name)\n",
    "        d2 = data_temp.loc[data_temp[column_name] == x]\n",
    "        d2 = d2.iloc[:,-1]\n",
    "        (class_vals, class_vals_count) = np.unique(d2, return_counts=True)\n",
    "        #print(class_vals, class_vals_count)  \n",
    "        label_count_dict[x] = class_vals_count\n",
    "    #print(\"$$$$$$$$ Label count dictionary is\", label_count_dict)\n",
    "\n",
    "    #entropy list stores the enropy for each feature variable \n",
    "    entropy_list = []\n",
    "    #calculate entropy as -plog(p)\n",
    "    for key in label_count_dict:\n",
    "        if(len(label_count_dict[key]) > 1):\n",
    "            neg_count = label_count_dict[key][0]\n",
    "            pos_count = label_count_dict[key][1]\n",
    "        #if ((pos_count != 0) or (neg_count != 0)):\n",
    "            p1 = pos_count/(pos_count + neg_count)\n",
    "            p2 = neg_count/(pos_count + neg_count)\n",
    "            entropy = -((p1*math.log2(p1))+ (p2*math.log2(p2)))\n",
    "            #print(\"Value of entropy is\", entropy)\n",
    "            entropy_list.append(entropy)\n",
    "        else:\n",
    "            entropy_list.append(0)\n",
    "    #print(\"Entropy list\", entropy_list)\n",
    "\n",
    "    #Calculating the total entropy for the column \n",
    "    total_entropy = 0\n",
    "    for x  in range(0, len(entropy_list)):\n",
    "        total_entropy = total_entropy + (entropy_list[x]*(vals_count[x]/total_data_samples))\n",
    "    #print(\"Total Entropy\", total_entropy)\n",
    "\n",
    "    return total_entropy\n",
    "\n",
    "def CalInformationGain(data, attributes):\n",
    "    '''\n",
    "    '''\n",
    "    total_data_samples = len(data)\n",
    "    #print(\"Total data samples\", total_data_samples)  \n",
    "    label_values = data.iloc[:,-1]\n",
    "    \n",
    "    class_labels, label_counts  = np.unique(label_values, return_counts=True)\n",
    "    #print(\"Class Labels\", class_labels)\n",
    "    #print(\"Label Count\", label_counts)\n",
    "\n",
    "    raw_entropy = 0\n",
    "    for x  in range(0, len(label_counts)):\n",
    "        p = label_counts[x]/total_data_samples\n",
    "        raw_entropy = raw_entropy -(p*math.log2(p))\n",
    "    #print(\"Raw entropy\", raw_entropy)\n",
    "\n",
    "    #information_gain_dict dictionary stores label of colum and IG corresponding to that \n",
    "    information_gain_dict = {}\n",
    "    #attributes = data.iloc[:,0:9].columns.values\n",
    "    for x in attributes:\n",
    "        information_gain_dict[x] = raw_entropy - CalEntropy(data, x)\n",
    "\n",
    "    #print(\"Dict of IG\", (information_gain_dict))\n",
    "    return information_gain_dict\n",
    "\n",
    "def select_best_feature(information_gain_dict):\n",
    "    sorted_information_gain_dict = sorted(information_gain_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #print(type(sorted_information_gain_dict))\n",
    "    max_ig_feature = next(iter(sorted_information_gain_dict))\n",
    "    ret = max_ig_feature[0]\n",
    "    #print(ret)\n",
    "    return ret \n",
    "\n",
    "class Node:\n",
    "    def __init__(self, value=None, edge=None):\n",
    "        self.value = value\n",
    "        self.edge = edge #edge to this node (coming to this node)\n",
    "        self.children = [] #list of Nodes\n",
    "    def __str__(self):\n",
    "        st = 'Node.value = '+str(self.value)+' edge_coming_to_me = '+str(self.edge)\n",
    "        return st\n",
    "\n",
    "#id3 tree will return the root node \n",
    "def id3(data, attributes, node):\n",
    "    #print(\"Attributes for this iteration are\", attributes)\n",
    "    root = Node()\n",
    "    root.edge = node.edge\n",
    "\n",
    "    #check if all examples are positive or negative \n",
    "    class_labels = data.iloc[:,-1]\n",
    "    labels, label_count = np.unique(class_labels, return_counts=True)\n",
    "    #print(labels, label_count)\n",
    "\n",
    "    if (len(labels) == 1):\n",
    "        root.value = labels\n",
    "        return root\n",
    "\n",
    "    '''\n",
    "    if (len(data) == 0):\n",
    "        root.value = \"END\"\n",
    "        return root\n",
    "    '''\n",
    "    '''\n",
    "    for x in range(0,len(labels)):\n",
    "        if label_count[x] == 0:\n",
    "            root.value = labels[(x+1)%2]\n",
    "            return root\n",
    "    '''\n",
    "\n",
    "    if attributes.size == 0:\n",
    "        if(label_count[0]>=label_count[1]):\n",
    "            root.value = labels[0]\n",
    "        else:\n",
    "            root.value = labels[1]\n",
    "        return root\n",
    "    else:\n",
    "        information_gain_dict = CalInformationGain(data, attributes)\n",
    "        A = select_best_feature(information_gain_dict)\n",
    "        root.value = A\n",
    "        root.children = []\n",
    "        values_of_A = data[A]\n",
    "        for e in values_of_A.unique():\n",
    "            child_node = Node()\n",
    "            #child_node.value = e\n",
    "            child_node.edge = e\n",
    "            #root.children.append(child_node)\n",
    "            #dominant_label = data['Class'].value_counts()[0]\n",
    "            data2 = data.loc[data[A] == e]\n",
    "            #if len(data) == 0:\n",
    "            #    child_node.edge = dominant_label\n",
    "            if(len(data)>0):\n",
    "                new_attributes = attributes[attributes != A]\n",
    "                #TODO:\n",
    "            #child_node.edge = id3(data, new_attributes)\n",
    "            child_node = id3(data2, new_attributes, child_node)\n",
    "            root.children.append(child_node)\n",
    "\n",
    "    return root\n",
    "\n",
    "#information_gain_dict = CalInformationGain(data, attributes)\n",
    "#select_best_feature(information_gain_dict)\n",
    "attributes = data_tic_tak.iloc[:,0:9].columns.values\n",
    "#print(attributes)\n",
    "#X = data.drop('Class', axis=1)\n",
    "#y = data['Class']\n",
    "\n",
    "data1 = pd.read_csv(\"./playtennis.csv\")\n",
    "attributes1 = data1.iloc[:,1:5].columns.values\n",
    "\n",
    "temp_node = Node()\n",
    "#root = id3(data_tic_tak, attributes, temp_node)\n",
    "root = id3(data1, attributes1, temp_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Node.value = Outlook edge_coming_to_me = None\nNode.value = Humidity edge_coming_to_me = Sunny\nNode.value = ['No'] edge_coming_to_me = High\nNode.value = ['Yes'] edge_coming_to_me = Normal\nNode.value = ['Yes'] edge_coming_to_me = Overcast\nNode.value = Wind edge_coming_to_me = Rain\nNode.value = ['Yes'] edge_coming_to_me = Weak\nNode.value = ['No'] edge_coming_to_me = Strong\n"
    }
   ],
   "source": [
    "def printNode(node):\n",
    "    #print(node.edge)\n",
    "    #print(node.value)\n",
    "    st = 'Node.value = '+str(node.value)+' edge_coming_to_me = '+str(node.edge)\n",
    "    print(st)\n",
    "\n",
    "def printTree(node):\n",
    "    if node:\n",
    "        printNode(node)\n",
    "        for c in node.children:\n",
    "           printTree(c)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "printTree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "No\n"
    }
   ],
   "source": [
    "class_labels = data1.iloc[:,-1]\n",
    "#class_labels = data_tic_tak.iloc[:,-1]\n",
    "labels, label_count = np.unique(class_labels, return_counts=True)\n",
    "def predict(tree, x_test, labels):\n",
    "    root = tree\n",
    "    predicted_val = ''\n",
    "    v = root.value\n",
    "    if v in labels:\n",
    "        predicted_val = v[0]\n",
    "        #print(\"predicted value = \", predicted_val)\n",
    "        return predicted_val\n",
    "    f = x_test[v]\n",
    "    for child in root.children:\n",
    "        if (f == child.edge):\n",
    "            predicted_val = predict(child, x_test, labels)\n",
    "    return predicted_val\n",
    "\n",
    "y = predict(root, data1.iloc[1,:], labels)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy:  98.54384133611691  %\nMean:  0.9854384133611691\nVariance 0.014349546833390715\n\n\t\tConfusion Matrix\ntrue_pos:  12374 \t\tfalse_neg:  158\nfalse_pos:  121 \t\ttrue_neg:  6507\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "def crossValidate(data1):\n",
    "    temp_node = Node()\n",
    "    class_labels = data1.iloc[:,-1]\n",
    "    labels = np.unique(class_labels)\n",
    "    y_predicted = []\n",
    "    y_actual    = []\n",
    "    y_accuracy  = []\n",
    "    Accuracy = 0\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    rkf = RepeatedKFold(n_splits=10, n_repeats=2, random_state=2652124)\n",
    "    for train_index, test_index in rkf.split(data1):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = data1.iloc[train_index, :], data1.iloc[test_index, :]\n",
    "        #print(X_test)\n",
    "        # train model \n",
    "        attributes = X_train.iloc[:,0:9].columns.values\n",
    "        root = id3(X_train, attributes, temp_node)\n",
    "\n",
    "\n",
    "        #validation \n",
    "        for _, test_row in data1.iterrows():\n",
    "            #print(test_row)\n",
    "            #print(type(test_row))\n",
    "            actual = test_row.iloc[-1]\n",
    "            predicted = predict(root, test_row, labels)\n",
    "            if actual == predicted:\n",
    "                if actual == 'positive':\n",
    "                    true_pos += 1\n",
    "                else:\n",
    "                    true_neg += 1\n",
    "            else:\n",
    "                if predicted == 'positive':\n",
    "                    false_pos += 1\n",
    "                else:\n",
    "                    false_neg += 1\n",
    "            y_actual.append(actual)\n",
    "            y_predicted.append(predicted)\n",
    "            y_accuracy.append(int(actual == predicted))\n",
    "\n",
    "    #print(\"y_actual: \", y_actual)\n",
    "    #print(\"y_predicted: \", y_predicted)\n",
    "    #print(\"y_accuracy: \", y_accuracy)\n",
    "    Accuracy = 100 * np.count_nonzero(y_accuracy)/len(y_accuracy)\n",
    "    Mean = np.mean(y_accuracy)\n",
    "    Variance = np.var(y_accuracy)\n",
    "    print(\"Accuracy: \", Accuracy, \" %\")\n",
    "    print(\"Mean: \", Mean)\n",
    "    print(\"Variance\", Variance)\n",
    "    print('\\n\\t\\tConfusion Matrix')\n",
    "    print(\"true_pos: \", true_pos, \"\\t\\tfalse_neg: \", false_neg)\n",
    "    print(\"false_pos: \", false_pos, \"\\t\\ttrue_neg: \", true_neg)\n",
    "    \n",
    "\n",
    "\n",
    "crossValidate(data_tic_tak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0      No\n1      No\n2     Yes\n3     Yes\n4     Yes\n5      No\n6     Yes\n7      No\n8     Yes\n9     Yes\n10    Yes\n11    Yes\n12    Yes\n13     No\nName: Play-Tennis, dtype: object\n[12]\n"
    },
    {
     "ename": "KeyError",
     "evalue": "'No'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-3f0e482dbddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdata_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddNoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-3f0e482dbddb>\u001b[0m in \u001b[0;36maddNoise\u001b[0;34m(data1, percent, single_column)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mvalue_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No'"
     ]
    }
   ],
   "source": [
    "def addNoiseColumn(value_list):\n",
    "    '''\n",
    "    column_series = single value pandas series\n",
    "    value_list = list of unique values in a column\n",
    "    '''\n",
    "    ind = np.random.randint(0, len(value_list))\n",
    "    return value_list[ind]\n",
    "\n",
    "def addNoise(data1, percent=.05, single_column=False):\n",
    "    data_1 = data1.sample(frac=percent)\n",
    "    print(data1)\n",
    "    indices = data_1.index.tolist()\n",
    "    print(indices)\n",
    "    data_1 = data1.copy()\n",
    "    value_list = {}\n",
    "    if single_column:\n",
    "        value_list = np.unique(data1)\n",
    "        for i in indices:\n",
    "            data_1[i] = addNoiseColumn(value_list)\n",
    "    else:\n",
    "        for c in data1:\n",
    "            value_list[c] = np.unique(data1[c])\n",
    "        for i in indices:\n",
    "            for c in data_1:\n",
    "                data_1[c][i] = addNoiseColumn(value_list[c])\n",
    "    print(data_1)\n",
    "    return data_1\n",
    "\n",
    "data_1 = addNoise(data1.iloc[:, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Day   Outlook Temperature Humidity    Wind Play-Tennis\n0     1     Sunny         Hot     High    Weak          No\n1     2     Sunny         Hot     High  Strong          No\n2     3  Overcast         Hot     High    Weak         Yes\n3     4      Rain        Mild     High    Weak         Yes\n4     5      Rain        Cool   Normal    Weak         Yes\n5     6      Rain        Cool   Normal  Strong          No\n6     7  Overcast        Cool   Normal  Strong         Yes\n7     8     Sunny        Mild     High    Weak          No\n8     9     Sunny        Cool   Normal    Weak         Yes\n9    10      Rain        Mild   Normal    Weak         Yes\n10   11     Sunny        Mild   Normal  Strong         Yes\n11   12  Overcast        Mild     High  Strong         Yes\n12   13  Overcast         Hot   Normal    Weak         Yes\n13   14      Rain        Mild     High  Strong          No\n[11, 8, 10, 9, 0, 3, 2]\n    Day   Outlook Temperature Humidity    Wind Play-Tennis\n0     9     Sunny        Mild   Normal  Strong          No\n1     2     Sunny         Hot     High  Strong          No\n2     1     Sunny        Mild     High    Weak         Yes\n3     5  Overcast         Hot   Normal  Strong         Yes\n4     5      Rain        Cool   Normal    Weak         Yes\n5     6      Rain        Cool   Normal  Strong          No\n6     7  Overcast        Cool   Normal  Strong         Yes\n7     8     Sunny        Mild     High    Weak          No\n8     4  Overcast         Hot   Normal    Weak          No\n9    10      Rain        Cool     High    Weak         Yes\n10    8     Sunny        Cool     High  Strong         Yes\n11    6      Rain        Cool   Normal  Strong          No\n12   13  Overcast         Hot   Normal    Weak         Yes\n13   14      Rain        Mild     High  Strong          No\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(data1)\n",
    "percent = 0.5\n",
    "\n",
    "print(data_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<__main__.Node object at 0x7f2506689a90>\nNode.value = middle-middle-square edge_coming_to_me = None\n"
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(root)\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testTrainSplit (x, y, train_split = .9, fold):\n",
    "    '''\n",
    "    x attribute data (pandas)\n",
    "    y class label column (pandas)\n",
    "    '''\n",
    "    len_data = len(x)\n",
    "    test_idx = int(len_data*train_split)\n",
    "    train_data = x.iloc[0:test_idx, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "middle-middle-square\n(top-left-square)\n(top-left-square)\n(top-left-square)\n"
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-2d253e968dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprintTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-2d253e968dc0>\u001b[0m in \u001b[0;36mprintTree\u001b[0;34m(node_)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroots\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "def printTree(node_):\n",
    "    if node_:\n",
    "        roots = deque()\n",
    "        roots.append(node_)\n",
    "        while len(roots) > 0:\n",
    "            root = roots.popleft()\n",
    "            print(root.value)\n",
    "            if root.children:\n",
    "                for child in root.children:\n",
    "                    print('({})'.format(child.value))\n",
    "                    roots.append(child.edge)\n",
    "            elif root.edge:\n",
    "                print(root.edge)\n",
    "\n",
    "printTree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1\n<__main__.Node object at 0x7f2507452a50>\n"
    }
   ],
   "source": [
    "class Node:\n",
    "\tdef __init__(self, value=None, edge=None):\n",
    "\t\tself.value = value\n",
    "\t\tself.edge = edge #edge to this node (coming to this node)\n",
    "\t\tself.childs = [] #list of Nodes\n",
    "\n",
    "'''\n",
    " for vi in values of bestAttr:\n",
    "    // For example, Outlook has three values: Sunny, Overcast, and Rain\n",
    "    insert value vi as branch of node\n",
    "    create viRows with rows that only contains value vi\n",
    "    if viRows is empty, then:\n",
    "      this node branch ended by a leaf with value is dominant label in x\n",
    "    else:\n",
    "      newY = list of attributes y with bestAttr removed\n",
    "      nextNode = next node connected by this branch\n",
    "      nextNode = ID3(viRows, newY, label, nextNode)\n",
    "  return node\n",
    "'''\n",
    "def id3(x, y, labels, node):\n",
    "    '''\n",
    "    x = training data without column names\n",
    "    y = column names or attributes\n",
    "    labels = labeled data (yes/no)\n",
    "    node = is a class\n",
    "    '''\n",
    "    node = Node()\n",
    "    c = np.unique(labels, count=True)\n",
    "    if(len(c) == 1):\n",
    "        node.value = c\n",
    "        return node \n",
    "    if x.empty():\n",
    "        node.value = #TODO\n",
    "        return node\n",
    "    \n",
    "    information_gain_dict = CalInformationGain(data, attributes)\n",
    "    best_attribute = select_best_feature(information_gain_dict)\n",
    "    node.value = best_attribute\n",
    "    best_attribute_vals = np.unique(x[best_attribute])\n",
    "\n",
    "    node.childs = []\n",
    "    for vi in best_attribute_vals:\n",
    "        child = Node()\n",
    "        child.edge = vi\n",
    "        #node.childs.append(child)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitinfo = -(attr_x * np.ma.log2(attr_x))-(attr_o * np.ma.log2(attr_o))-(attr_b * np.ma.log2(attr_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tic_tac_node:\n",
    "\n",
    "    def __init__(self, o_node, x_node, b_node, idxs, min_leaf=5):\n",
    "        self.o_node = o_node \n",
    "        self.x_node = x_node\n",
    "        self.b_node = b_node\n",
    "        self.idxs = idxs \n",
    "        self.min_leaf = min_leaf\n",
    "        self.row_count = len(idxs)\n",
    "        self.col_count = x.shape[1]\n",
    "        self.val = np.mean(y[idxs])\n",
    "        self.score = float('inf')\n",
    "        self.find_varsplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Calculates the Information Gain Ratio  \n",
    "def info_gain_ratio(target, feature = [], uniques = []):\n",
    "    entropy = 0\n",
    "    denominator_1 = feature.count()\n",
    "    data = pd.concat([pd.DataFrame(target.values.reshape((target.shape[0], 1))), feature], axis = 1)\n",
    "    for entp in range(0, len(np.unique(target))):\n",
    "        numerator_1 = data.iloc[:,0][(data.iloc[:,0] == np.unique(target)[entp])].count()\n",
    "        if numerator_1 > 0:\n",
    "            entropy = entropy - (numerator_1/denominator_1)* np.log2((numerator_1/denominator_1))\n",
    "    info_gain = float(entropy)\n",
    "    info_gain_r = 0\n",
    "    intrinsic_v = 0\n",
    "    for word in range(0, len(uniques)):\n",
    "        denominator_2 = feature[(feature == uniques[word])].count()\n",
    "        if denominator_2[0] > 0:\n",
    "            intrinsic_v = intrinsic_v - (denominator_2/denominator_1)* np.log2((denominator_2/denominator_1))\n",
    "        for lbl in range(0, len(np.unique(target))):\n",
    "            numerator_2 = data.iloc[:,0][(data.iloc[:,0] == np.unique(target)[lbl]) & (data.iloc[:,1]  == uniques[word])].count()\n",
    "            if numerator_2 > 0:\n",
    "                info_gain = info_gain + (denominator_2/denominator_1)*(numerator_2/denominator_2)* np.log2((numerator_2/denominator_2))\n",
    "    if intrinsic_v[0] > 0:\n",
    "        info_gain_r = info_gain/intrinsic_v\n",
    "    return float(info_gain_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x        -- training example \n",
    "# label    -- class label \n",
    "# features -- set of attributes\n",
    "# samples  -- number of samples \n",
    "\n",
    "class decision_tree(object):\n",
    "    def __init__(self, samples, features, labels)\n",
    "    self.samples  = samples\n",
    "    self.features = features\n",
    "    self.labels   = labels\n",
    "    self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tic_tac_dt(data):\n",
    "    node = tic_tac(True, )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TicTac():\n",
    "    def __init__(self, node_if_leaf, clssfiction, prnt, b_child, o_child,x_child, height):\n",
    "\n",
    "        self.clssfiction = None\n",
    "        self.split_atribute = None\n",
    "        self.prnt = prnt\n",
    "        self.b_child = None\n",
    "        self.o_child = None\n",
    "        self.x_child = None\n",
    "        self.height = None\n",
    "        self.node_if_leaf = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "7\n"
    }
   ],
   "source": [
    "class Id3():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.MAX = 7\n",
    "        self.new_values = []\n",
    "        self.target_attribute = None\n",
    "        self.attributes = []\n",
    "        print(self.MAX)\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self):\n",
    "        self.id3 = Id3()\n",
    "\n",
    "    def cal_entropy(self, max_int):\n",
    "        pass\n",
    "\n",
    "    def add_leaf_node(self):\n",
    "        pass  \n",
    "\n",
    "dt = DecisionTree()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntropy(self, sampleIds):\n",
    "\t\tentropy = 0\n",
    "\t\tlabelCount = [0] * len(self.labelCodes)\n",
    "\t\tfor sid in sampleIds:\n",
    "\t\t\tlabelCount[self.getLabelCodeId(sid)] += 1\n",
    "\t\t# print(\"-ge\", labelCount)\n",
    "\t\tfor lv in labelCount:\n",
    "\t\t\t# print(lv)\n",
    "\t\t\tif lv != 0:\n",
    "\t\t\t\tentropy += -lv/len(sampleIds) * math.log(lv/len(sampleIds), 2)\n",
    "\t\t\telse:\n",
    "\t\t\t\tentropy += 0\n",
    "\t\treturn entropy\n",
    "\n",
    "\tdef getInformationGain(self, sampleIds, attributeId):\n",
    "\t\tgain = self.getEntropy(sampleIds)\n",
    "\t\tattributeVals = []\n",
    "\t\tattributeValsCount = []\n",
    "\t\tattributeValsIds = []\n",
    "\t\tfor sid in sampleIds:\n",
    "\t\t\tval = self.sample[sid][attributeId]\n",
    "\t\t\tif val not in attributeVals:\n",
    "\t\t\t\tattributeVals.append(val)\n",
    "\t\t\t\tattributeValsCount.append(0)\n",
    "\t\t\t\tattributeValsIds.append([])\n",
    "\t\t\tvid = attributeVals.index(val)\n",
    "\t\t\tattributeValsCount[vid] += 1\n",
    "\t\t\tattributeValsIds[vid].append(sid)\n",
    "\t\t# print(\"-gig\", self.attributes[attributeId])\n",
    "\t\tfor vc, vids in zip(attributeValsCount, attributeValsIds):\n",
    "\t\t\t# print(\"-gig\", vids)\n",
    "\t\t\tgain -= vc/len(sampleIds) * self.getEntropy(vids)\n",
    "\t\treturn gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('tic-tac-toe.csv')"
   ]
  }
 ]
}